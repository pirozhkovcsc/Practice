{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Терминология"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Статистически значимый результат** — результат, который статистически значимо лучше 0.\n",
    "- **Прокрас теста** — результат эксперимента статистически значимо отличается от 0, и у вас есть какой-то эффект.\n",
    "- **Зелёный тест** — метрика в A/B-тесте статистически значимо стала лучше.\n",
    "- **Красный тест** — метрика в A/B-тесте статистически значимо стала хуже.\n",
    "- **Серый тест** — результат A/B-теста не статистически значим.\n",
    "- **Тритмент** — фича или предложение, чьё воздействие на пользователей вы проверяете в A/B-тесте.\n",
    "- **MDE** — минимальный детектируемый эффект. Размер, который должен иметь истинный эффект от тритмента, чтобы эксперимент его обнаружил с заданной долей уверенности (мощностью). Чем меньше MDE, тем лучше.\n",
    "- **Мощность критерия** — вероятность критерия задетектировать эффект, если он действительно есть. Чем больше мощность критерия, тем он круче. \n",
    "- **Предпериод** — период до начала эксперимента.\n",
    "- T - тестовая группа\n",
    "- C - контрольная группа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что важнее и предпочтительней?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. При анализе A/B-тестов считайте не только p-value, но и доверительные интервалы с численными оценками эффекта. \n",
    "2. Считайте не только абсолютные метрики, но и относительные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм проверки статистических критериев"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея простая:\n",
    "\n",
    "1. Создаём как можно больше датасетов, поделённых на контроль и тест, без какого-либо различия между ними (обычный А/А-тест). \n",
    "\n",
    "2. Прогоняем на них придуманный критерий.\n",
    "\n",
    "3. Если мы хотим, чтобы ошибка первого рода была 5%, то критерий должен ошибиться на этих примерах лишь в 5% случаев. То есть 0 не попал в доверительный интервал. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Абсолютный Т-тест"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим абсолютный критерий следующим образом: будем проверять гипотезу $H_0 = \\{\\mathbb{E}(T) = \\mathbb{E}(C)\\}$, против сложной классической альтернативы $H_1 = \\{\\mathbb{E}(T) \\neq \\mathbb{E}(C)\\}$. Для этого мы заведем функцию `absolute_ttest`, в которой на заданном уровне значимости $\\alpha$ будем тестировать гипотезу о наличии эффекта."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Импорт всех нужных библиотек.\n",
    "from collections import namedtuple\n",
    "import scipy.stats as sps\n",
    "import statsmodels.stats.api as sms\n",
    "from tqdm.notebook import tqdm as tqdm_notebook # tqdm – библиотека для визуализации прогресса в цикле\n",
    "from collections import defaultdict\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "import numpy as np\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.5, palette='Set2')\n",
    "ExperimentComparisonResults = namedtuple('ExperimentComparisonResults', \n",
    "                                        ['pvalue', 'effect', 'ci_length', 'left_bound', 'right_bound'])\n",
    "\n",
    "# 2. Создание тестируемого критерия\n",
    "def absolute_ttest(control, test, alpha=0.05):\n",
    "    mean_control = np.mean(control)\n",
    "    mean_test = np.mean(test)\n",
    "    var_mean_control  = np.var(control) / len(control)\n",
    "    var_mean_test  = np.var(test) / len(test)\n",
    "    \n",
    "    difference_mean = mean_test - mean_control\n",
    "    difference_mean_var = var_mean_control + var_mean_test\n",
    "    difference_distribution = sps.norm(loc=difference_mean, scale=np.sqrt(difference_mean_var))\n",
    "\n",
    "    left_bound, right_bound = difference_distribution.ppf([alpha / 2, 1 - alpha / 2])\n",
    "    ci_length = (right_bound - left_bound)\n",
    "    pvalue = 2 * min(difference_distribution.cdf(0), difference_distribution.sf(0))\n",
    "    effect = difference_mean\n",
    "    return ExperimentComparisonResults(pvalue, effect, ci_length, left_bound, right_bound)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Эксперимент 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь просто реализуем A/A тест с помощью функции, построенной выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_1(N=100000, size_control=1500, size_test=1500, loc_1=1, loc_2=1):\n",
    "    # 3. Заводим счётчик.\n",
    "    bad_cnt = 0\n",
    "\n",
    "    # 4. Цикл проверки.\n",
    "    for i in range(N):\n",
    "        # 4.a. Тестирую A/A-тест.\n",
    "        control = sps.expon.rvs(loc=loc_1, size=size_control)\n",
    "        test = sps.expon.rvs(loc=loc_2, size=size_test)\n",
    "        \n",
    "        # 4.b. Запускаю критерий.\n",
    "        _, _, _, left_bound, right_bound = absolute_ttest(control, test)\n",
    "\n",
    "        # 4.c. Проверяю, лежит ли истинная разница средних в доверительном интервале.\n",
    "        if left_bound > 0 or right_bound < 0:\n",
    "            bad_cnt += 1\n",
    "\n",
    "    # 5. Строю доверительный интервал для конверсии ошибок у критерия.\n",
    "    left_ci, right_ci = proportion_confint(count=bad_cnt, nobs=N)\n",
    "    return bad_cnt / N, left_ci, right_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Реально достигнутый уровень значимости = 0.059\n",
      "\n",
      "Левая и правая граница доверительного интервала для alpha_real = (0.0444, 0.0736)\n"
     ]
    }
   ],
   "source": [
    "alpha_real, left_ci, right_ci = experiment_1(N=1000, size_control=500, size_test=600, loc_1=1000, loc_2=1000)\n",
    "\n",
    "print(f\"Реально достигнутый уровень значимости = {round(alpha_real, 4)}\",\n",
    "      f\"Левая и правая граница доверительного интервала для alpha_real = {round(left_ci, 4), round(right_ci, 4)}\",\n",
    "      sep='\\n\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала валидируйте критерий на искусственных датасетах, чтобы точнее оценить, не ошибается ли он на простых распределениях. И лишь после этого переходите к датасетам на реальных данных.\n",
    "\n",
    "Таким образом мы прогоняем наши критерии только на А/А-тестах. Но на самом деле можно эмулировать и A/B-тесты. Казалось бы, зачем, но про это расскажем позже."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь поговорим про относительный Т-тест критерий."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Относительный Т-тест."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Создание тестируемого критерия.\n",
    "def relative_ttest(control, test, alpha=0.05):\n",
    "    mean_control = np.mean(control)\n",
    "    mean_test = np.mean(test)\n",
    "    var_mean_control  = np.var(control) / len(control)\n",
    "    var_mean_test  = np.var(test) / len(test)\n",
    "\n",
    "    difference_mean = mean_test - mean_control\n",
    "    difference_mean_var = var_mean_control + var_mean_test\n",
    "    difference_distribution = sps.norm(loc=difference_mean, scale=np.sqrt(difference_mean_var))\n",
    "\n",
    "    left_bound, right_bound = difference_distribution.ppf([alpha / 2, 1 - alpha / 2])\n",
    "    left_bound = left_bound / np.mean(control)   # Деление на среднее в контроле\n",
    "    right_bound = right_bound / np.mean(control) # Деление на среднее в контроле\n",
    "\n",
    "    ci_length = (right_bound - left_bound)\n",
    "    pvalue = 2 * min(difference_distribution.cdf(0), difference_distribution.sf(0))\n",
    "    effect = difference_mean\n",
    "    return ExperimentComparisonResults(pvalue, effect, ci_length, left_bound, right_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_2(N=10000, size_control=1500, size_test=1500, loc_1=1, loc_2=1):\n",
    "    # 3. Заводим счётчик.\n",
    "    bad_cnt = 0\n",
    "\n",
    "    # 4. Цикл проверки.\n",
    "    for i in range(N):\n",
    "        # 4.a. Тестирую A/A-тест.\n",
    "        control = sps.expon.rvs(loc=loc_1, size=size_control)\n",
    "        test = sps.expon.rvs(loc=loc_2, size=size_test)\n",
    "        \n",
    "        # 4.b. Запускаю критерий.\n",
    "        _, _, _, left_bound, right_bound = relative_ttest(control, test)\n",
    "\n",
    "        # 4.c. Проверяю, лежит ли истинная разница средних в доверительном интервале.\n",
    "        if left_bound > 0 or right_bound < 0:\n",
    "            bad_cnt += 1\n",
    "\n",
    "    # 5. Строю доверительный интервал для конверсии ошибок у критерия.\n",
    "    left_ci, right_ci = proportion_confint(count=bad_cnt, nobs=N)\n",
    "    return bad_cnt / N, left_ci, right_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Реально достигнутый уровень значимости = 0.054\n",
      "\n",
      "Левая и правая граница доверительного интервала для alpha_real = (0.04, 0.068)\n"
     ]
    }
   ],
   "source": [
    "alpha_real, left_ci, right_ci = experiment_2(N=1000, size_control=500, size_test=600, loc_1=1000, loc_2=1000)\n",
    "\n",
    "print(f\"Реально достигнутый уровень значимости = {round(alpha_real, 4)}\",\n",
    "      f\"Левая и правая граница доверительного интервала для alpha_real = {round(left_ci, 4), round(right_ci, 4)}\",\n",
    "      sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Методы борьбы с выбросами в данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим следующие выборки в контроле и тесте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_control = [3] * 30 + [10] * 30 + [200] * 10 + [1200]\n",
    "sample_test    = [8] * 30 + [20] * 30 + [100] * 10 + [1000]\n",
    "\n",
    "sample_control = np.array(sample_control) + sps.norm().rvs(len(sample_control)) # придадим шума\n",
    "sample_test    = np.array(sample_test) + sps.norm().rvs(len(sample_test)) # придадим шума"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, в данном случае есть 4 группы пользователей. Как мы видим, в группах с низкой метрикой значения на тесте значительно выше (в относительном смысле), чего нельзя сказать о группе с высокой метрикой - там, наоборот, значения на тесте ниже!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте попробуем применить несколько критериев и проинтерпретируем их:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=0.45076353541881664, pvalue=0.6735713334513904)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sps.ttest_ind(sample_control, sample_test, alternative='less')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, гипотеза о том, что метрика в тесте выше, не подтверждается. Здесь мы использовали `ttest_ind` - это Т-тест Уэлча. Подробнее можно посмотреть вот: [здесь](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь примением критерий Манна-Уитни и тот же Т-тест, но уже предварительно применив к выборкам функцию `np.log(x + 1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=1566.0, pvalue=9.927514766857255e-05)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sps.mannwhitneyu(sample_control, sample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-2.7161797510335854, pvalue=0.0037184565231908806)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sps.ttest_ind(np.log(sample_control + 1), np.log(sample_test + 1), alternative='less')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь у нас гипотеза подтверждается. Т.е метрика на тесте значимо выше, чем на контроле. Тритмент есть, выкатываем фичу!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напоследок убедимся, что метрика на тесте и правда выше, чем на контроле:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50.340143144786325, 39.906954925606826)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(sample_control), np.mean(sample_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да уж, здесь метрика на тесте значительно ниже, чем на контроле. Но ведь два последних теста говорят нам об обратном."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что делать?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема в том, что тест Манна-Уитни проверяет совершенно другую гипотезу (об этом можно посмотреть в ноутбуке про критерий Манна-Уитни). Аналогично при логарифмировании у нас снова нулевая гипотеза - это совсем не то, что нужно."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первом же тесте `ttest_ind(alternative='less)` мы вообще проверяли другую гипотезу. У нас метрика на контроле явно доминирует над метрикой на тесте. Давайте посмотрим, значимо ли это происходит в настоящий момент времени или нет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=0.45076353541881664, pvalue=0.3264286665486095)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sps.ttest_ind(sample_control, sample_test, alternative='greater')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нет, пока что это происходит не значимо. Возможно, если выборка станет побольше, то мы все-таки увидим значимую разницу (ведь она и правда довольно большая)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Увеличим выборки, сохранив пропорции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_control = [3] * 30 * 100 + [10] * 30 * 100 + [200] * 10 * 100 + [1200] * 100\n",
    "sample_test    = [8] * 30 * 100 + [20] * 30 * 100 + [100] * 10 * 100 + [1000] * 100\n",
    "\n",
    "sample_control = np.array(sample_control) + sps.norm().rvs(len(sample_control)) # придадим шума\n",
    "sample_test    = np.array(sample_test) + sps.norm().rvs(len(sample_test)) # придадим шума"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на метрики (тест/контроль):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50.56518580346066, 39.9986873187836)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(sample_control), np.mean(sample_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь посмотрим, значимо ли наша метрика ухудшилась после добавления фичи, т.е на тесте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=4.597886281757246, pvalue=2.1524103725766345e-06)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sps.ttest_ind(sample_control, sample_test, alternative='greater')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да! Стоило лишь немного подождать."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какой вывод мы можем сделать?\n",
    "- Не нужно использовать критерии, которые проверяют совершенно другую гипотезу. Т.е тест Манна-Уитни и логарифмирование + Т-тест не дадут вам правильный ответ + запутают в интерпретации.\n",
    "- Иногда для прокраса теста нужно время, поэтому достаточно подождать нужного размера выборки (об этом более подробно во второй части)\n",
    "- Проверяйте бизнес-метрики на тесте и контроле перед самим тестом. На глаз можно понять, как вообще влияет наша фича. Затем уже можно запускать критерий.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном кейсе у нас были очевидные выбросы (1200 и 1000 на контроле и тесте соответственно). Давайте посмотрим, как можно бороться с выбросами и откидывать топ n%."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Убрать топ 1% пользователей с максимальной метрикой в тесте и контроле"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(N=10000, size_control=1500, size_test=1500, loc_1=1, loc_2=1):\n",
    "    # 3. Заводим счётчик.\n",
    "    bad_cnt = 0\n",
    "\n",
    "    # 4. Цикл проверки.\n",
    "    for i in range(N):\n",
    "        # 4.a. Тестирую A/A-тест.\n",
    "        control = sps.expon.rvs(loc=loc_1, size=size_control)\n",
    "        test = sps.expon.rvs(loc=loc_2, size=size_test)\n",
    "\n",
    "        outlier_control_filter = np.quantile(control, 0.99)\n",
    "        outlier_test_filter = np.quantile(test, 0.99)\n",
    "        \n",
    "        control = control[control < outlier_control_filter] # убираем топ 1% в контроле\n",
    "        test    = test[test < outlier_test_filter] # убираем топ 1% в тесте\n",
    "        \n",
    "        # 4.b. Запускаю критерий.\n",
    "        _, _, _, left_bound, right_bound = relative_ttest(control, test)\n",
    "\n",
    "        # 4.c. Проверяю, лежит ли истинная разница средних в доверительном интервале.\n",
    "        if left_bound > 0 or right_bound < 0:\n",
    "            bad_cnt += 1\n",
    "\n",
    "    # 5. Строю доверительный интервал для конверсии ошибок у критерия.\n",
    "    left_ci, right_ci = proportion_confint(count=bad_cnt, nobs=N)\n",
    "    return bad_cnt / N, left_ci, right_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Реально достигнутый уровень значимости = 0.069\n",
      "\n",
      "Левая и правая граница доверительного интервала для alpha_real = (0.0662, 0.0719)\n"
     ]
    }
   ],
   "source": [
    "alpha_real, left_ci, right_ci = experiment(N=30000, size_control=500, size_test=600, loc_1=1000, loc_2=1000)\n",
    "\n",
    "print(f\"Реально достигнутый уровень значимости = {round(alpha_real, 4)}\",\n",
    "      f\"Левая и правая граница доверительного интервала для alpha_real = {round(left_ci, 4), round(right_ci, 4)}\",\n",
    "      sep='\\n\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, реально достигнутый уровень значимости далек от 0.05. Почему так происходит?\n",
    "\n",
    "**Первая проблема:**\n",
    "Дело в том, что из-за выбросов у нас выборочные квантили могут иметь совершенно разный порядок. Поэтому один из кейсов, что в одной выборке значения могут быть меньше 2000, а в другой - меньше 3000."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы исправить этот недостаток, можно брать **одну** квантиль для теста и контроля, посчитанную на всём тесте или на всём контроле или на объединенной выборке теста и контроля. На А/А-тестах такая вещь работает. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(N=10000, size_control=1500, size_test=1500, loc_1=1, loc_2=1):\n",
    "    # 3. Заводим счётчик.\n",
    "    bad_cnt = 0\n",
    "\n",
    "    # 4. Цикл проверки.\n",
    "    for i in range(N):\n",
    "        # 4.a. Тестирую A/A-тест.\n",
    "        control = sps.expon.rvs(loc=loc_1, size=size_control)\n",
    "        test = sps.expon.rvs(loc=loc_2, size=size_test)\n",
    "\n",
    "        outlier_filter = np.quantile(np.concatenate([control, test]), 0.99)\n",
    "        \n",
    "        control = control[control < outlier_filter] # убираем топ 1% в контроле\n",
    "        test    = test[test < outlier_filter] # убираем топ 1% в тесте\n",
    "        \n",
    "        # 4.b. Запускаю критерий.\n",
    "        _, _, _, left_bound, right_bound = relative_ttest(control, test)\n",
    "\n",
    "        # 4.c. Проверяю, лежит ли истинная разница средних в доверительном интервале.\n",
    "        if left_bound > 0 or right_bound < 0:\n",
    "            bad_cnt += 1\n",
    "\n",
    "    # 5. Строю доверительный интервал для конверсии ошибок у критерия.\n",
    "    left_ci, right_ci = proportion_confint(count=bad_cnt, nobs=N)\n",
    "    return bad_cnt / N, left_ci, right_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Реально достигнутый уровень значимости = 0.0502\n",
      "\n",
      "Левая и правая граница доверительного интервала для alpha_real = (0.0477, 0.0527)\n"
     ]
    }
   ],
   "source": [
    "alpha_real, left_ci, right_ci = experiment(N=30000, size_control=500, size_test=600, loc_1=1000, loc_2=1000)\n",
    "\n",
    "print(f\"Реально достигнутый уровень значимости = {round(alpha_real, 4)}\",\n",
    "      f\"Левая и правая граница доверительного интервала для alpha_real = {round(left_ci, 4), round(right_ci, 4)}\",\n",
    "      sep='\\n\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такая вещь работает, потому что мы выбираем один порог для двух выборок. При этом обьединяя их - мы учитываем как выбросы в контроле, так и выбросы в тесте. Тем самым находя что-то среднее (ведь выборки из одного распределения)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часть 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CUPED (Controlled-experiment Using Pre-Experiment Data) — очень популярный в последнее время метод уменьшения вариации.\n",
    "\n",
    "Основная идея метода такова: давайте вычтем что-то из теста и из контроля так, чтобы математическое ожидание разницы новых величин осталось таким же, как было, а дисперсия уменьшилась."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Более формально:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть $T$ - метрика на тестовой выборке, а $C$ - на контрольной. Будем как обычно проверять гипотезу $H_0 = \\{\\mathbb{E}(T) = \\mathbb{E}(C)\\}$, против сложной классической альтернативы $H_1 = \\{\\mathbb{E}(T) \\neq \\mathbb{E}(C)\\}$. Итак, рассмотрим новые случайные величины $T^{'}$ и $C^{'}$ такие, что\n",
    "\\begin{align*}\n",
    "    T^{'} : = T - \\theta \\cdot A \\text{ и}\\\\\n",
    "    C^{'} : = C - \\theta \\cdot B,\n",
    "\\end{align*}\n",
    "где $\\theta$ - некоторая константа, а $A$ и $B$ независимые случайные величины такие, что $\\mathbb{E}(A) = \\mathbb{E}(B)$. Тогда верно, что\n",
    "\\begin{align*}\n",
    "    \\mathbb{E}(T^{'} - C^{'}) &= \\mathbb{E}(T^{'}) - \\mathbb{E}(C^{'}) \\\\\n",
    "    &= (\\mathbb{E}(T) - \\mathbb{E}(C)) - \\theta \\cdot (\\mathbb{E}(A) - \\mathbb{E}(B)) \\\\\n",
    "    &= \\mathbb{E}(T) - \\mathbb{E}(C)\n",
    "\\end{align*}\n",
    "Т.е матожидание разницы новых метрик такое же, как матожидание разницы старых метрик, а также $T^{'} и C^{'}$ независимы. Поэтому можно рассматривать аналогичную задачу, т.е проверять гипотезу $H_0 = \\{\\mathbb{E}(T^{'}) = \\mathbb{E}(C^{'})\\}$, против альтернативы $H_1 = \\{\\mathbb{E}(T^{'}) \\neq \\mathbb{E}(C^{'})\\}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь наша цель - понижение дисперсии разницы новых метрик, т.е \n",
    "\\begin{align*}\n",
    "    \\argmin_{\\theta} \\{\\mathbb{D}(T^{'} - C^{'})\\} \\Leftrightarrow \\\\\n",
    "    \\argmin_{\\theta} \\{\\mathbb{D}((T - C) - \\theta \\cdot (A - B))\\} \\Leftrightarrow \\\\\n",
    "    \\argmin_{\\theta} \\{\\mathbb{D}(T - C) + {\\theta}^2 \\cdot \\mathbb{D}(A - B) - 2 \\cdot \\theta \\cdot \\mathrm{Cov}[T - C, A - B]\\} \n",
    "\\end{align*}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Легко заметить, что мы получили квадратное уравнение в зависимости от $\\theta$. Очевидно, минимум достигается в точке\n",
    "\\begin{align*}\n",
    "    \\theta^{*} = \\frac{\\mathrm{Cov}[T - C, A - B]}{\\mathbb{D}(A - B)}.\n",
    "\\end{align*}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также отметим, что дисперсия разницы новых метрик при $\\theta = {\\theta}^{*}$ равна \n",
    "\\begin{align*}\n",
    "    \\mathbb{D}(T^{'} - C^{'}) &= \\mathbb{D}(T - C) + {\\left(\\frac{\\mathrm{Cov}[T - C, A - B]}{\\mathbb{D}(A - B)}\\right)}^2 \\cdot \\mathbb{D}(A - B) - 2 \\cdot \\frac{\\mathrm{Cov}[T - C, A - B]}{\\mathbb{D}(A - B)} \\cdot \\mathrm{Cov}[T - C, A - B] \\\\\n",
    "    &= \\mathbb{D}(T - C) - {\\left(\\frac{\\left(\\mathrm{Cov}[T - C, A - B]\\right)^2}{\\mathbb{D}(A - B)}\\right)} = \\mathbb{D}(T - C) - \\mathbb{D}(T - C) \\cdot {\\left(\\frac{\\left(\\mathrm{Cov}[T - C, A - B]\\right)^2}{\\mathbb{D}(A - B) \\cdot \\mathbb{D}(T - C)}\\right)} \\\\\n",
    "    &= \\mathbb{D}(T - C) \\cdot \\left(1 - {\\left(\\frac{\\left(\\mathrm{Cov}[T - C, A - B]\\right)^2}{\\mathbb{D}(A - B) \\cdot \\mathbb{D}(T - C)}\\right)}\\right) = \\mathbb{D}(T - C) \\cdot (1 - {\\alpha}^2),\n",
    "\\end{align*}\n",
    "где $\\alpha = \\mathrm{Corr}[T - C, A - B]$.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отсюда следует несколько фактов:\n",
    "1. Дисперсия у разницы новых метрик всегда ниже, чем дисперсия разницы старых метрик.\n",
    "2. Если мы хотим еще сильнее уменьшить дисперсию разницы новых метрик, то нужно делать так, чтобы $T - C$ и $A - B$ сильно коррелировали. Этого можно добиться тем, что на предпериоде мы будем случайно бить на тест и контроль и в качестве $A$ будем брать тест на предпериоде, а в качестве B - контроль на предпериоде. Понятно также, что математические ожидания у $A$ и $B$ должны быть равны и так будет тогда и только тогда, когда A/A тест будет успешно проходить! (а он и обязан успешно проходить, иначе дальнейшие действия бессмысленны) Кроме значения метрики на предпериоде можно использовать результаты ML-модели, обученной предсказывать истинные значения метрик без влияния тритмента. С хорошей моделью можно достичь большего уменьшения дисперсии."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно провести симмуляцию и посмотреть, как сильно мы будем выигрывать в дисперсии разницы новых метрик:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем для этого функцию `cuped_ttest`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Создание функции cuped_ttest\n",
    "def cuped_ttest(control, test, control_before, test_before):\n",
    "    theta = (np.cov(control, control_before)[0, 1] + np.cov(test, test_before)[0, 1]) \\\n",
    "          / (np.var(test_before) + np.var(control_before))\n",
    "    \n",
    "    new_test = test - theta * test_before\n",
    "    new_control = control - theta * control_before\n",
    "    \n",
    "    return absolute_ttest(control=new_control, test=new_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем симмуляцию A/A теста для построенных cuped-метрик:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc9d09e75da84c19a1cb2933352b81fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Реальный уровень значимости: 1.0\n",
      "Доверительный интервал: [0.9999, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# 3. Заводим счётчик.\n",
    "bad_cnt = 0\n",
    "\n",
    "# 4. Цикл проверки.\n",
    "N = 30000\n",
    "for i in tqdm_notebook(range(N)):\n",
    "    # 4.a. Тестирую A/A-тест.\n",
    "    control_before = sps.expon(scale=1000).rvs(1000)\n",
    "    test_before = sps.expon(scale=1000).rvs(1000)\n",
    "\n",
    "    control = control_before + sps.norm(loc=0, scale=100).rvs(1000)\n",
    "    test = test_before + sps.norm(loc=0, scale=100).rvs(1000)\n",
    "    test *= 1\n",
    "\n",
    "    # 4.b. Запускаю критерий.\n",
    "    _, _, _, left_bound, right_bound = cuped_ttest(control, test, control_before, test_before)\n",
    "    \n",
    "    # 4.c. Проверяю, лежит ли истинная разница средних в доверительном интервале. Если не лежит - увеличиваю счетчик на 1.\n",
    "    if left_bound > 100 or right_bound < 100:\n",
    "        bad_cnt += 1\n",
    "        \n",
    "# 5. Строю доверительный интервал для конверсии ошибок у критерия.\n",
    "left_real_level, right_real_level = proportion_confint(count = bad_cnt, nobs = N, alpha=0.05, method='wilson')\n",
    "\n",
    "# Результат.\n",
    "print(f\"Реальный уровень значимости: {round(bad_cnt / N, 4)}\",\n",
    "      f\"Доверительный интервал: [{round(left_real_level, 4)}, {round(right_real_level, 4)}]\", sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте ещё посмотрим, на сколько в искусственном примере уменьшилась ширина доверительного интервала по сравнению с обычным T-test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cccc00e1f1ce4b95bc2b685ec4f81db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доверительный интервал для cuped_ttest относительно доверительного интервала для ttest уменьшился в 10.05 раз.\n"
     ]
    }
   ],
   "source": [
    "# 3. Заводим счётчик.\n",
    "bad_cnt = 0\n",
    "\n",
    "ci_length_cuped_ttest_arr = [] # здесь будем хранить длины доверительных интервалов для cuped_ttest\n",
    "ci_length_ttest_arr = [] # здесь будем хранить длины доверительных интервалов для ttest\n",
    "\n",
    "# 4. Цикл проверки.\n",
    "N = 30000\n",
    "for i in tqdm_notebook(range(N)):\n",
    "    # 4.a. Тестирую A/A-тест.\n",
    "    control_before = sps.expon(scale=1000).rvs(1000)\n",
    "    test_before = sps.expon(scale=1000).rvs(1000)\n",
    "\n",
    "    control = control_before + sps.norm(loc=0, scale=100).rvs(1000)\n",
    "    test = test_before + sps.norm(loc=0, scale=100).rvs(1000)\n",
    "    test *= 1\n",
    "\n",
    "    # 4.b. Запускаю критерий.\n",
    "    _, _, ci_length_cuped_ttest, _, _ = cuped_ttest(control, test, control_before, test_before)\n",
    "    _, _, ci_length_ttest, _, _ = absolute_ttest(control, test)\n",
    "\n",
    "    # 4.c. Добавляем в списки полученные длины\n",
    "\n",
    "    ci_length_cuped_ttest_arr.append(ci_length_cuped_ttest)\n",
    "    ci_length_ttest_arr.append(ci_length_ttest)\n",
    "\n",
    "        \n",
    "# 5. Строю доверительный интервал для конверсии ошибок у критерия.\n",
    "left_real_level, right_real_level = proportion_confint(count = bad_cnt, nobs = N, alpha=0.05, method='wilson')\n",
    "\n",
    "coeff = round(np.array(ci_length_ttest_arr).mean() / np.array(ci_length_cuped_ttest_arr).mean(), 2)\n",
    "# Результат.\n",
    "print(f\"Доверительный интервал для cuped_ttest относительно доверительного интервала для ttest уменьшился в {coeff} раз.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86b34ed3c3133d18abca1a7478c638bf2ec364040bada6a3f6362ac01a633aad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
